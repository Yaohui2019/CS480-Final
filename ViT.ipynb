{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81655,"databundleVersionId":8915386,"sourceType":"competition"},{"sourceId":9159549,"sourceType":"datasetVersion","datasetId":5533689}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport imageio.v3 as imageio\nimport albumentations as A\n\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport timm\nimport glob\nimport torchmetrics\nimport time\nimport psutil\nimport os\n\ntqdm.pandas()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-12T15:44:22.724676Z","iopub.execute_input":"2024-08-12T15:44:22.725042Z","iopub.status.idle":"2024-08-12T15:44:22.732488Z","shell.execute_reply.started":"2024-08-12T15:44:22.725015Z","shell.execute_reply":"2024-08-12T15:44:22.731378Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Config():\n    IMAGE_SIZE = 384\n    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n    N_TARGETS = len(TARGET_COLUMNS)\n    BATCH_SIZE = 10\n    LR_MAX = 1e-4\n    WEIGHT_DECAY = 0.01\n    N_EPOCHS = 3\n    TRAIN_MODEL = True\n    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n        \nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T15:44:38.927822Z","iopub.execute_input":"2024-08-12T15:44:38.928217Z","iopub.status.idle":"2024-08-12T15:44:38.934194Z","shell.execute_reply.started":"2024-08-12T15:44:38.928186Z","shell.execute_reply":"2024-08-12T15:44:38.933168Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/train.csv')\ntrain['file_path'] = train['id'].apply(lambda s: f'/kaggle/input/cs-480-2024-spring/data/train_images/{s}.jpeg')\ntrain['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\ntrain.to_pickle('train.pkl')\n\nfor column in CONFIG.TARGET_COLUMNS:\n    lower_quantile = train[column].quantile(0.005)\n    upper_quantile = train[column].quantile(0.985)  \n    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n\nCONFIG.N_TRAIN_SAMPLES = len(train)\nCONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\nCONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n\ntest = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/test.csv')\ntest['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/cs-480-2024-spring/data/test_images/{s}.jpeg')\ntest['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\ntest.to_pickle('test.pkl')\n\nprint('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))","metadata":{"execution":{"iopub.status.busy":"2024-08-12T15:45:11.726769Z","iopub.execute_input":"2024-08-12T15:45:11.727413Z","iopub.status.idle":"2024-08-12T15:47:58.551620Z","shell.execute_reply.started":"2024-08-12T15:45:11.727381Z","shell.execute_reply":"2024-08-12T15:47:58.550666Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/43363 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ac35d3836b485e9a789f855ae1e525"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe463bce42a04636bc1b02e88a6f732f"}},"metadata":{}},{"name":"stdout","text":"N_TRAIN_SAMPLES: 38422 N_TEST_SAMPLES: 6391\n","output_type":"stream"}]},{"cell_type":"code","source":"LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n\ny_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\nfor target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n    v = train[target].values\n    if target in LOG_FEATURES:\n        v = np.log10(v)\n    y_train[:, target_idx] = v\n\nSCALER = StandardScaler()\ny_train = SCALER.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T15:48:01.184230Z","iopub.execute_input":"2024-08-12T15:48:01.184652Z","iopub.status.idle":"2024-08-12T15:48:01.208482Z","shell.execute_reply.started":"2024-08-12T15:48:01.184604Z","shell.execute_reply":"2024-08-12T15:48:01.207652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"MEAN = np.array([0.485, 0.456, 0.406])\nSTD = np.array([0.229, 0.224, 0.225])\n\nTRAIN_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nclass Dataset(Dataset):\n    def __init__(self, X_jpeg_bytes, y, transforms=None):\n        self.X_jpeg_bytes = X_jpeg_bytes\n        self.y = y\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X_jpeg_bytes)\n\n    def __getitem__(self, index):\n        X_sample = self.transforms(\n            image=imageio.imread(self.X_jpeg_bytes[index]),\n        )['image']\n        y_sample = self.y[index]\n        \n        return X_sample, y_sample\n\ntrain_dataset = Dataset(\n    train['jpeg_bytes'].values,\n    y_train,\n    TRAIN_TRANSFORMS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=CONFIG.BATCH_SIZE,\n        shuffle=True,\n        drop_last=True,\n        num_workers=psutil.cpu_count(),\n)\n\ntest_dataset = Dataset(\n    test['jpeg_bytes'].values,\n    test['id'].values,\n    TEST_TRANSFORMS,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T15:48:03.327300Z","iopub.execute_input":"2024-08-12T15:48:03.328218Z","iopub.status.idle":"2024-08-12T15:48:03.340876Z","shell.execute_reply.started":"2024-08-12T15:48:03.328185Z","shell.execute_reply":"2024-08-12T15:48:03.339742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import ViTModel\n\n# Assuming you have already trained the ViTWithMLP model\n# vit = ViTModel.from_pretrained('google/vit-large-patch16-384')\n\nclass ViTWithMLP(nn.Module):\n    def __init__(self, vit,hidden_dim,output_dim):\n        super(ViTWithMLP, self).__init__()\n        self.vit = vit\n        self.mlp = nn.Sequential(\n            nn.Linear(vit.config.hidden_size, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim)  # Final layer to be removed\n        )\n    \n    def forward(self, x):\n        outputs = self.vit(pixel_values=x)\n        features = outputs.last_hidden_state[:, 0, :]\n        output = self.mlp(features)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T16:04:58.093998Z","iopub.execute_input":"2024-08-12T16:04:58.094349Z","iopub.status.idle":"2024-08-12T16:05:02.802190Z","shell.execute_reply.started":"2024-08-12T16:04:58.094323Z","shell.execute_reply":"2024-08-12T16:05:02.801396Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/models/model.pth')\nmodel.to('cuda')\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T16:05:08.197610Z","iopub.execute_input":"2024-08-12T16:05:08.198101Z","iopub.status.idle":"2024-08-12T16:05:19.748008Z","shell.execute_reply.started":"2024-08-12T16:05:08.198071Z","shell.execute_reply":"2024-08-12T16:05:19.746954Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"ViTWithMLP(\n  (vit): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x ViTLayer(\n          (attention): ViTSdpaAttention(\n            (attention): ViTSdpaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViTPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (mlp): Sequential(\n    (0): Linear(in_features=1024, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=6, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def get_lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=CONFIG.LR_MAX,\n        total_steps=CONFIG.N_STEPS,\n        pct_start=0.1,\n        anneal_strategy='cos',\n        div_factor=1e1,\n        final_div_factor=1e1,\n    )\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val):\n        self.sum += val.sum()\n        self.count += val.numel()\n        self.avg = self.sum / self.count\n\nMAE = torchmetrics.regression.MeanAbsoluteError().to('cuda')\nR2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\nLOSS = AverageMeter()\n\nY_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\nEPS = torch.tensor([1e-6]).to('cuda')\n\ndef r2_loss(y_pred, y_true):\n    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n    ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n    ss_total = torch.maximum(ss_total, EPS)\n    r2 = torch.mean(ss_res / ss_total)\n    return r2\n\nLOSS_FN = nn.SmoothL1Loss() # r2_loss\n\noptimizer = torch.optim.AdamW(\n    params=model.parameters(),\n    lr=CONFIG.LR_MAX,\n    weight_decay=CONFIG.WEIGHT_DECAY,\n)\n\nLR_SCHEDULER = get_lr_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T15:52:24.736749Z","iopub.execute_input":"2024-08-12T15:52:24.737423Z","iopub.status.idle":"2024-08-12T15:52:24.767600Z","shell.execute_reply.started":"2024-08-12T15:52:24.737388Z","shell.execute_reply":"2024-08-12T15:52:24.766666Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Freeze transformers for first epoch\nfor param in model.vit.parameters():\n    param.requires_grad = False\n    \nprint(\"Start Training:\")\nfor epoch in range(CONFIG.N_EPOCHS):\n    MAE.reset()\n    R2.reset()\n    LOSS.reset()\n    model.train()\n        \n    for step, (X_batch, y_true) in enumerate(train_dataloader):\n        X_batch = X_batch.to('cuda')\n        y_true = y_true.to('cuda')\n        t_start = time.perf_counter_ns()\n        y_pred = model(X_batch)\n        loss = LOSS_FN(y_pred, y_true)\n        LOSS.update(loss)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        LR_SCHEDULER.step()\n        MAE.update(y_pred, y_true)\n        R2.update(y_pred, y_true)\n        \n        #Unfreeze\n        if epoch == 0:\n            for param in model.vit.parameters():\n                param.requires_grad = True\n        \n        \n        if not CONFIG.IS_INTERACTIVE and (step+1) == CONFIG.N_STEPS_PER_EPOCH:\n            print(\n                f'EPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n            )\n        elif CONFIG.IS_INTERACTIVE:\n            print(\n                f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n                end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n            )\n    #Unfreeze\n    if epoch == 0:\n        for param in model.vit.parameters():\n            param.requires_grad = True\n\ntorch.save(model, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-12T03:56:08.806607Z","iopub.execute_input":"2024-08-12T03:56:08.806961Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Start Training:\nEPOCH 01, 0130/3842 | loss: 0.3351, mae: 0.6434, r2: 0.0319, step: 1.955s, lr: 1.10e-055","output_type":"stream"}]}]}